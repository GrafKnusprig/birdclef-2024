{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%rm -r /kaggle/working/*"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T08:06:47.440608Z","iopub.status.busy":"2024-07-11T08:06:47.440255Z","iopub.status.idle":"2024-07-11T08:07:00.469305Z","shell.execute_reply":"2024-07-11T08:07:00.468203Z","shell.execute_reply.started":"2024-07-11T08:06:47.440581Z"},"trusted":true},"outputs":[],"source":["%pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T08:07:00.472159Z","iopub.status.busy":"2024-07-11T08:07:00.471606Z","iopub.status.idle":"2024-07-11T08:07:15.737517Z","shell.execute_reply":"2024-07-11T08:07:15.736570Z","shell.execute_reply.started":"2024-07-11T08:07:00.472118Z"},"trusted":true},"outputs":[],"source":["%pip install noisereduce numpy tqdm librosa optuna timm scikit-metrics pandas pillow"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T08:36:18.609218Z","iopub.status.busy":"2024-07-11T08:36:18.608465Z","iopub.status.idle":"2024-07-11T08:36:19.870523Z","shell.execute_reply":"2024-07-11T08:36:19.869633Z","shell.execute_reply.started":"2024-07-11T08:36:18.609183Z"},"trusted":true},"outputs":[],"source":["# This create a small subset for testing\n","\n","import os\n","import shutil\n","import sys\n","\n","def copy_files(src_root, dest_root):\n","    # Create the destination root directory if it doesn't exist\n","    os.makedirs(dest_root, exist_ok=True)\n","\n","    # Get the first 10 subdirectories\n","    subdirs = [os.path.join(src_root, d) for d in os.listdir(src_root) if os.path.isdir(os.path.join(src_root, d))]\n","    subdirs = subdirs[:10]\n","\n","    for subdir in subdirs:\n","        # Get the first 5 files in the current subdirectory\n","        files = [os.path.join(subdir, f) for f in os.listdir(subdir) if os.path.isfile(os.path.join(subdir, f))]\n","        files = files[:5]\n","\n","        # Create the corresponding subdirectory in the destination\n","        dest_subdir = os.path.join(dest_root, os.path.basename(subdir))\n","        os.makedirs(dest_subdir, exist_ok=True)\n","\n","        for file in files:\n","            shutil.copy(file, dest_subdir)\n","    \n","    print(\"Copying completed.\")\n","\n","src_root = '/kaggle/input/birdclef-2024/train_audio'\n","dest_root = '/kaggle/working/train_audio_subset'\n","\n","copy_files(src_root, dest_root)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T08:37:06.386125Z","iopub.status.busy":"2024-07-11T08:37:06.385664Z","iopub.status.idle":"2024-07-11T08:56:14.290641Z","shell.execute_reply":"2024-07-11T08:56:14.289764Z","shell.execute_reply.started":"2024-07-11T08:37:06.386086Z"},"trusted":true},"outputs":[],"source":["import multiprocessing\n","import os\n","import time\n","from pathlib import Path\n","from io import BytesIO\n","from PIL import Image\n","import pandas as pd\n","\n","import librosa\n","import matplotlib.pyplot as plt\n","import noisereduce as nr\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader, random_split\n","import timm\n","import optuna\n","from sklearn.metrics import roc_auc_score\n","\n","_input_folder = \"/kaggle/input/birdclef-2024/train_audio\"\n","_input_folder = '/kaggle/working/train_audio_subset'\n","_test_folder = \"/kaggle/input/birdclef-2024/test_soundscapes\"\n","_output_model_folder = \"/kaggle/working/models\"\n","_output_log_folder = \"/kaggle/working/logs\"\n","_output_submission_folder = \"/kaggle/working\"\n","sample_rate = 16000\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def load_audio(filename):\n","    audio, sr = librosa.load(filename, sr=sample_rate)\n","    return audio, sr\n","\n","def segment_audio(segment, segment_length=5, sr=sample_rate):\n","    segmented_chunks = []\n","    samples_per_segment = segment_length * sr\n","    for start in range(0, len(segment), samples_per_segment):\n","        end = start + samples_per_segment\n","        segmented_chunks.append(segment[start:end])\n","    return segmented_chunks\n","\n","def generate_square_spectrogram(audio, sr, size=224, fmin=2000, fmax=8000):\n","    s = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=fmax, fmin=fmin)\n","    s_dB = librosa.power_to_db(s, ref=np.max)\n","    fig, ax = plt.subplots(figsize=(size / 100, size / 100), dpi=100)\n","    img = librosa.display.specshow(s_dB, sr=sr, x_axis='time', y_axis='mel', fmin=fmin, fmax=fmax, cmap='gray', ax=ax)\n","    ax.axis('off')\n","    plt.tight_layout(pad=0)\n","    buf = BytesIO()\n","    fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n","    plt.close(fig)\n","    buf.seek(0)\n","    image = Image.open(buf).convert('RGB')\n","    return image\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, file_pairs, transform=None):\n","        self.file_pairs = file_pairs\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return sum(len(segment) for _, _, segment in self.file_pairs)\n","\n","    def __getitem__(self, idx):\n","        current_idx = 0\n","        for input_file_path, label, segments in self.file_pairs:\n","            if idx < current_idx + len(segments):\n","                segment = segments[idx - current_idx]\n","                image = generate_square_spectrogram(segment, sample_rate)  # Using sample_rate\n","                if self.transform:\n","                    image = self.transform(image)\n","                return image, label\n","            current_idx += len(segments)\n","        raise IndexError(\"Index out of range\")\n","\n","def prepare_file_pairs(input_folder):\n","    file_pairs = []\n","    input_folder = Path(input_folder)\n","    class_names = sorted([f.name for f in input_folder.iterdir() if f.is_dir()])\n","    class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n","    \n","    for input_path in input_folder.rglob('*.ogg'):\n","        label = class_to_idx[input_path.parent.name]\n","        audio, sr = load_audio(input_path)\n","        audio = nr.reduce_noise(audio, sr)\n","        segments = segment_audio(audio, segment_length=5, sr=sr)\n","        file_pairs.append((input_path, label, segments))\n","    return file_pairs, len(class_names)\n","\n","def objective(trial):\n","    model = timm.create_model('resnext50_32x4d', pretrained=True)\n","\n","    transformation = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    file_pairs, num_classes = prepare_file_pairs(_input_folder)\n","    dataset = CustomDataset(file_pairs, transform=transformation)\n","\n","    train_size = int(0.8 * len(dataset))\n","    val_size = len(dataset) - train_size\n","    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n","\n","    model.fc = nn.Linear(model.fc.in_features, num_classes)\n","\n","    model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=trial.suggest_loguniform(\"lr\", 1e-5, 1e-1))\n","\n","    num_epochs = 5\n","    train_losses = []\n","    val_losses = []\n","    train_accuracies = []\n","    val_accuracies = []\n","    val_roc_aucs = []\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","\n","        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","        for inputs, labels in train_loader_tqdm:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            total_train += labels.size(0)\n","            correct_train += (predicted == labels).sum().item()\n","\n","            train_loader_tqdm.set_postfix(loss=loss.item())\n","\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        epoch_accuracy = 100 * correct_train / total_train\n","        train_losses.append(epoch_loss)\n","        train_accuracies.append(epoch_accuracy)\n","\n","        val_loss = 0.0\n","        correct_val = 0\n","        total_val = 0\n","        all_labels = []\n","        all_probs = []\n","\n","        model.eval()\n","        val_loader_tqdm = tqdm(val_loader, desc=\"Validating\")\n","\n","        with torch.no_grad():\n","            for inputs, labels in val_loader_tqdm:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item() * inputs.size(0)\n","                _, predicted = torch.max(outputs, 1)\n","                total_val += labels.size(0)\n","                correct_val += (predicted == labels).sum().item()\n","\n","                all_labels.extend(labels.cpu().numpy())\n","                all_probs.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n","\n","                val_loader_tqdm.set_postfix(val_loss=loss.item())\n","\n","        epoch_val_loss = val_loss / len(val_loader.dataset)\n","        epoch_val_accuracy = 100 * correct_val / total_val\n","        val_losses.append(epoch_val_loss)\n","        val_accuracies.append(epoch_val_accuracy)\n","\n","        roc_auc = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n","        val_roc_aucs.append(roc_auc)\n","\n","        trial.report(epoch_val_accuracy, epoch)\n","\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","    # Save the model after tuning\n","    os.makedirs(_output_model_folder, exist_ok=True)\n","    model_save_path = f\"{_output_model_folder}/model_best_resnext_trial_{trial.number}.pth\"\n","    torch.save(model.state_dict(), model_save_path)\n","\n","    return val_accuracies[-1]\n","\n","# Set up logging\n","os.makedirs(_output_log_folder, exist_ok=True)\n","log_file = f\"{_output_log_folder}/training_log.txt\"\n","\n","def log_message(message):\n","    print(message)\n","    with open(log_file, 'a') as f:\n","        f.write(message + '\\n')\n","\n","# Set up the Optuna study\n","study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=3, timeout=600)\n","\n","log_message(f\"Number of finished trials: {len(study.trials)}\")\n","log_message(\"Best trial:\")\n","trial = study.best_trial\n","\n","log_message(f\"  Value: {trial.value}\")\n","log_message(\"  Params: \")\n","for key, value in trial.params.items():\n","    log_message(f\"    {key}: {value}\")\n","\n","# Save the best model\n","file_pairs, num_classes = prepare_file_pairs(_input_folder)\n","best_model = timm.create_model('resnext50_32x4d', pretrained=True)\n","best_model.fc = nn.Linear(best_model.fc.in_features, num_classes)\n","best_model.load_state_dict(torch.load(f\"{_output_model_folder}/model_best_resnext_trial_{trial.number}.pth\"))\n","best_model_save_path = f\"{_output_model_folder}/model_best_resnext.pth\"\n","torch.save(best_model.state_dict(), best_model_save_path)\n","\n","log_message(f\"Best model saved to {best_model_save_path}\")\n","\n","# Load and test the best model\n","best_model.load_state_dict(torch.load(best_model_save_path))\n","best_model.eval()\n","best_model.to(device)\n","\n","test_transformation = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","test_file_pairs, _ = prepare_file_pairs(_test_folder)\n","test_dataset = CustomDataset(test_file_pairs, transform=test_transformation)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","submission = []\n","\n","with torch.no_grad():\n","    for idx, (inputs, _) in enumerate(tqdm(test_loader, desc=\"Testing\")):\n","        inputs = inputs.to(device)\n","        outputs = best_model(inputs)\n","        probs = torch.nn.functional.softmax(outputs, dim=1).cpu().numpy().flatten()\n","        \n","        # Generate row_id\n","        row_id = os.path.basename(test_file_pairs[idx][0]).replace('.ogg', '')\n","        \n","        submission.append([row_id] + probs.tolist())\n","\n","# Create submission DataFrame\n","column_names = ['row_id'] + [f'label_{i}' for i in range(num_classes)]\n","submission_df = pd.DataFrame(submission, columns=column_names)\n","\n","# Save to CSV\n","submission_csv_path = f\"{_output_submission_folder}/Submission.csv\"\n","submission_df.to_csv(submission_csv_path, index=False)\n","log_message(f\"Submission file saved to {submission_csv_path}\")\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":8068726,"sourceId":70203,"sourceType":"competition"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
