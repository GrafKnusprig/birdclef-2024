{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70203,"databundleVersionId":8068726,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -r /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-07-11T10:03:18.611855Z","iopub.execute_input":"2024-07-11T10:03:18.612270Z","iopub.status.idle":"2024-07-11T10:03:19.683112Z","shell.execute_reply.started":"2024-07-11T10:03:18.612236Z","shell.execute_reply":"2024-07-11T10:03:19.681781Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118","metadata":{"execution":{"iopub.status.busy":"2024-07-11T10:03:19.686031Z","iopub.execute_input":"2024-07-11T10:03:19.686853Z","iopub.status.idle":"2024-07-11T10:03:31.832729Z","shell.execute_reply.started":"2024-07-11T10:03:19.686813Z","shell.execute_reply":"2024-07-11T10:03:31.831680Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install noisereduce numpy tqdm librosa optuna timm scikit-metrics pandas pillow","metadata":{"execution":{"iopub.status.busy":"2024-07-11T10:03:31.834171Z","iopub.execute_input":"2024-07-11T10:03:31.834494Z","iopub.status.idle":"2024-07-11T10:03:44.249566Z","shell.execute_reply.started":"2024-07-11T10:03:31.834466Z","shell.execute_reply":"2024-07-11T10:03:44.248023Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Requirement already satisfied: noisereduce in /opt/conda/lib/python3.10/site-packages (3.0.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.2.post1)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.1)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (1.0.3)\nRequirement already satisfied: scikit-metrics in /opt/conda/lib/python3.10/site-packages (0.1.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from noisereduce) (1.11.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from noisereduce) (3.7.5)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.58.1)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.12.1)\nRequirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.8.1)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3.7)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.9.0)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.0.7)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.23.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.41.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (3.11.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.3.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (1.4.5)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# # This create a small subset for testing\n\n# import os\n# import shutil\n# import sys\n\n# def copy_files(src_root, dest_root):\n#     # Create the destination root directory if it doesn't exist\n#     os.makedirs(dest_root, exist_ok=True)\n\n#     # Get the first 10 subdirectories\n#     subdirs = [os.path.join(src_root, d) for d in os.listdir(src_root) if os.path.isdir(os.path.join(src_root, d))]\n#     subdirs = subdirs[:5]\n\n#     for subdir in subdirs:\n#         # Get the first 5 files in the current subdirectory\n#         files = [os.path.join(subdir, f) for f in os.listdir(subdir) if os.path.isfile(os.path.join(subdir, f))]\n#         files = files[:5]\n\n#         # Create the corresponding subdirectory in the destination\n#         dest_subdir = os.path.join(dest_root, os.path.basename(subdir))\n#         os.makedirs(dest_subdir, exist_ok=True)\n\n#         for file in files:\n#             shutil.copy(file, dest_subdir)\n    \n#     print(\"Copying completed.\")\n\n# src_root = '/kaggle/input/birdclef-2024/train_audio'\n# dest_root = '/kaggle/working/train_audio_subset'\n\n# copy_files(src_root, dest_root)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T10:03:44.253965Z","iopub.execute_input":"2024-07-11T10:03:44.254516Z","iopub.status.idle":"2024-07-11T10:03:44.810084Z","shell.execute_reply.started":"2024-07-11T10:03:44.254473Z","shell.execute_reply":"2024-07-11T10:03:44.809143Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Copying completed.\n","output_type":"stream"}]},{"cell_type":"code","source":"import multiprocessing\nimport os\nimport time\nfrom pathlib import Path\nfrom io import BytesIO\nfrom PIL import Image\nimport pandas as pd\n\nimport librosa\nimport matplotlib.pyplot as plt\nimport noisereduce as nr\nimport numpy as np\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader, random_split\nimport timm\nimport optuna\nfrom sklearn.metrics import roc_auc_score\n\n_input_folder = \"/kaggle/input/birdclef-2024/train_audio\"\n# _input_folder = '/kaggle/working/train_audio_subset' # For testing only\n_test_folder = \"/kaggle/input/birdclef-2024/test_soundscapes\"\n_output_model_folder = \"/kaggle/working/models\"\n_output_log_folder = \"/kaggle/working/logs\"\n_output_submission_folder = \"/kaggle/working\"\n_sample_rate = 16000\n_n_epochs = 5\n_n_optuna_trials = 3\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef load_audio(filename):\n    audio, sr = librosa.load(filename, sr=_sample_rate)\n    return audio, sr\n\ndef segment_audio(segment, segment_length=5, sr=_sample_rate):\n    segmented_chunks = []\n    samples_per_segment = segment_length * sr\n    for start in range(0, len(segment), samples_per_segment):\n        end = start + samples_per_segment\n        segmented_chunks.append(segment[start:end])\n    return segmented_chunks\n\ndef generate_square_spectrogram(audio, sr, size=224, fmin=2000, fmax=8000):\n    s = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=fmax, fmin=fmin)\n    s_dB = librosa.power_to_db(s, ref=np.max)\n    fig, ax = plt.subplots(figsize=(size / 100, size / 100), dpi=100)\n    img = librosa.display.specshow(s_dB, sr=sr, x_axis='time', y_axis='mel', fmin=fmin, fmax=fmax, cmap='gray', ax=ax)\n    ax.axis('off')\n    plt.tight_layout(pad=0)\n    buf = BytesIO()\n    fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n    plt.close(fig)\n    buf.seek(0)\n    image = Image.open(buf).convert('RGB')\n    return image\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, file_pairs, transform=None):\n        self.file_pairs = file_pairs\n        self.transform = transform\n\n    def __len__(self):\n        return sum(len(segment) for _, _, segment in self.file_pairs)\n\n    def __getitem__(self, idx):\n        current_idx = 0\n        for input_file_path, label, segments in self.file_pairs:\n            if idx < current_idx + len(segments):\n                segment = segments[idx - current_idx]\n                image = generate_square_spectrogram(segment, _sample_rate)\n                if self.transform:\n                    image = self.transform(image)\n                return image, label\n            current_idx += len(segments)\n        raise IndexError(\"Index out of range\")\n\ndef prepare_file_pairs(input_folder):\n    file_pairs = []\n    input_folder = Path(input_folder)\n    class_names = sorted([f.name for f in input_folder.iterdir() if f.is_dir()])\n    class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n    \n    for input_path in input_folder.rglob('*.ogg'):\n        label = class_to_idx[input_path.parent.name]\n        audio, sr = load_audio(input_path)\n        audio = nr.reduce_noise(audio, sr)\n        segments = segment_audio(audio, segment_length=5, sr=sr)\n        file_pairs.append((input_path, label, segments))\n    return file_pairs, len(class_names)\n\ndef objective(trial):\n    model = timm.create_model('resnext50_32x4d', pretrained=True)\n\n    transformation = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    file_pairs, num_classes = prepare_file_pairs(_input_folder)\n    dataset = CustomDataset(file_pairs, transform=transformation)\n\n    train_size = int(0.8 * len(dataset))\n    val_size = len(dataset) - train_size\n    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n\n    model.fc = nn.Linear(model.fc.in_features, num_classes)\n\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=trial.suggest_loguniform(\"lr\", 1e-5, 1e-1))\n\n    train_losses = []\n    val_losses = []\n    train_accuracies = []\n    val_accuracies = []\n    val_roc_aucs = []\n\n    for epoch in range(_n_epochs):\n        model.train()\n        running_loss = 0.0\n        correct_train = 0\n        total_train = 0\n\n        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{_n_epochs}\")\n\n        for inputs, labels in train_loader_tqdm:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total_train += labels.size(0)\n            correct_train += (predicted == labels).sum().item()\n\n            train_loader_tqdm.set_postfix(loss=loss.item())\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_accuracy = 100 * correct_train / total_train\n        train_losses.append(epoch_loss)\n        train_accuracies.append(epoch_accuracy)\n\n        val_loss = 0.0\n        correct_val = 0\n        total_val = 0\n        all_labels = []\n        all_probs = []\n\n        model.eval()\n        val_loader_tqdm = tqdm(val_loader, desc=\"Validating\")\n\n        with torch.no_grad():\n            for inputs, labels in val_loader_tqdm:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total_val += labels.size(0)\n                correct_val += (predicted == labels).sum().item()\n\n                all_labels.extend(labels.cpu().numpy())\n                all_probs.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n\n                val_loader_tqdm.set_postfix(val_loss=loss.item())\n\n        epoch_val_loss = val_loss / len(val_loader.dataset)\n        epoch_val_accuracy = 100 * correct_val / total_val\n        val_losses.append(epoch_val_loss)\n        val_accuracies.append(epoch_val_accuracy)\n\n        roc_auc = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n        val_roc_aucs.append(roc_auc)\n\n        trial.report(epoch_val_accuracy, epoch)\n\n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n\n    # Save the model after tuning\n    os.makedirs(_output_model_folder, exist_ok=True)\n    model_save_path = f\"{_output_model_folder}/model_best_resnext_trial_{trial.number}.pth\"\n    torch.save(model.state_dict(), model_save_path)\n\n    return val_accuracies[-1]\n\n# Set up logging\nos.makedirs(_output_log_folder, exist_ok=True)\nlog_file = f\"{_output_log_folder}/training_log.txt\"\n\ndef log_message(message):\n    print(message)\n    with open(log_file, 'a') as f:\n        f.write(message + '\\n')\n\n# Set up the Optuna study\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=_n_optuna_trials, timeout=600)\n\nlog_message(f\"Number of finished trials: {len(study.trials)}\")\nlog_message(\"Best trial:\")\ntrial = study.best_trial\n\nlog_message(f\"  Value: {trial.value}\")\nlog_message(\"  Params: \")\nfor key, value in trial.params.items():\n    log_message(f\"    {key}: {value}\")\n\n# Save the best model\nfile_pairs, num_classes = prepare_file_pairs(_input_folder)\nbest_model = timm.create_model('resnext50_32x4d', pretrained=True)\nbest_model.fc = nn.Linear(best_model.fc.in_features, num_classes)\nbest_model.load_state_dict(torch.load(f\"{_output_model_folder}/model_best_resnext_trial_{trial.number}.pth\"))\nbest_model_save_path = f\"{_output_model_folder}/model_best_resnext.pth\"\ntorch.save(best_model.state_dict(), best_model_save_path)\n\nlog_message(f\"Best model saved to {best_model_save_path}\")\n\n# Load and test the best model\nbest_model.load_state_dict(torch.load(best_model_save_path))\nbest_model.eval()\nbest_model.to(device)\n\ntest_transformation = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_file_pairs, _ = prepare_file_pairs(_test_folder)\ntest_dataset = CustomDataset(test_file_pairs, transform=test_transformation)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n\nsubmission = []\n\nwith torch.no_grad():\n    for idx, (inputs, _) in enumerate(tqdm(test_loader, desc=\"Testing\")):\n        inputs = inputs.to(device)\n        outputs = best_model(inputs)\n        probs = torch.nn.functional.softmax(outputs, dim=1).cpu().numpy().flatten()\n        \n        # Generate row_id\n        row_id = os.path.basename(test_file_pairs[idx][0]).replace('.ogg', '')\n        \n        submission.append([row_id] + probs.tolist())\n\n# Create submission DataFrame\ncolumn_names = ['row_id'] + [f'label_{i}' for i in range(num_classes)]\nsubmission_df = pd.DataFrame(submission, columns=column_names)\n\n# Save to CSV\nsubmission_csv_path = f\"{_output_submission_folder}/Submission.csv\"\nsubmission_df.to_csv(submission_csv_path, index=False)\nlog_message(f\"Submission file saved to {submission_csv_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T10:03:44.812392Z","iopub.execute_input":"2024-07-11T10:03:44.812718Z","iopub.status.idle":"2024-07-11T10:09:42.247689Z","shell.execute_reply.started":"2024-07-11T10:03:44.812686Z","shell.execute_reply":"2024-07-11T10:09:42.246736Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"[I 2024-07-11 10:03:44,858] A new study created in memory with name: no-name-8548b9fb-3ade-4004-90a1-218a3883bd5d\n/tmp/ipykernel_34/3275294766.py:119: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  optimizer = optim.Adam(model.parameters(), lr=trial.suggest_loguniform(\"lr\", 1e-5, 1e-1))\nEpoch 1/5: 100%|██████████| 9/9 [00:18<00:00,  2.03s/it, loss=1.6] \nValidating: 100%|██████████| 3/3 [00:04<00:00,  1.33s/it, val_loss=1.63]\nEpoch 2/5: 100%|██████████| 9/9 [00:18<00:00,  2.03s/it, loss=1.53]\nValidating: 100%|██████████| 3/3 [00:04<00:00,  1.39s/it, val_loss=1.55]\nEpoch 3/5: 100%|██████████| 9/9 [00:16<00:00,  1.84s/it, loss=1.57]\nValidating: 100%|██████████| 3/3 [00:04<00:00,  1.53s/it, val_loss=1.57]\nEpoch 4/5: 100%|██████████| 9/9 [00:16<00:00,  1.89s/it, loss=1.52]\nValidating: 100%|██████████| 3/3 [00:04<00:00,  1.61s/it, val_loss=1.57]\nEpoch 5/5: 100%|██████████| 9/9 [00:17<00:00,  1.94s/it, loss=1.42]\nValidating: 100%|██████████| 3/3 [00:03<00:00,  1.30s/it, val_loss=1.56]\n[I 2024-07-11 10:05:40,882] Trial 0 finished with value: 17.142857142857142 and parameters: {'batch_size': 16, 'lr': 3.368857767096308e-05}. Best is trial 0 with value: 17.142857142857142.\n/tmp/ipykernel_34/3275294766.py:119: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  optimizer = optim.Adam(model.parameters(), lr=trial.suggest_loguniform(\"lr\", 1e-5, 1e-1))\nEpoch 1/5: 100%|██████████| 9/9 [00:17<00:00,  1.97s/it, loss=1.32]\nValidating: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it, val_loss=7.77]\nEpoch 2/5: 100%|██████████| 9/9 [00:17<00:00,  1.95s/it, loss=1.1] \nValidating: 100%|██████████| 3/3 [00:04<00:00,  1.39s/it, val_loss=2.23]\nEpoch 3/5: 100%|██████████| 9/9 [00:18<00:00,  2.02s/it, loss=1.41] \nValidating: 100%|██████████| 3/3 [00:04<00:00,  1.44s/it, val_loss=12.8]\nEpoch 4/5: 100%|██████████| 9/9 [00:16<00:00,  1.87s/it, loss=1.04] \nValidating: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it, val_loss=6.75]\nEpoch 5/5: 100%|██████████| 9/9 [00:18<00:00,  2.08s/it, loss=0.487]\nValidating: 100%|██████████| 3/3 [00:03<00:00,  1.31s/it, val_loss=1.99]\n[I 2024-07-11 10:07:37,887] Trial 1 finished with value: 31.428571428571427 and parameters: {'batch_size': 16, 'lr': 0.009898835022645975}. Best is trial 1 with value: 31.428571428571427.\n/tmp/ipykernel_34/3275294766.py:119: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  optimizer = optim.Adam(model.parameters(), lr=trial.suggest_loguniform(\"lr\", 1e-5, 1e-1))\nEpoch 1/5: 100%|██████████| 5/5 [00:17<00:00,  3.45s/it, loss=1.54]\nValidating: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it, val_loss=1.56]\nEpoch 2/5: 100%|██████████| 5/5 [00:17<00:00,  3.53s/it, loss=1.55]\nValidating: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it, val_loss=1.44]\nEpoch 3/5: 100%|██████████| 5/5 [00:19<00:00,  3.95s/it, loss=1.26]\nValidating: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it, val_loss=1.3] \nEpoch 4/5: 100%|██████████| 5/5 [00:17<00:00,  3.52s/it, loss=1.21]\nValidating: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it, val_loss=1.15]\nEpoch 5/5: 100%|██████████| 5/5 [00:16<00:00,  3.40s/it, loss=1.17] \nValidating: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it, val_loss=1.07]\n[I 2024-07-11 10:09:34,640] Trial 2 finished with value: 40.0 and parameters: {'batch_size': 32, 'lr': 0.00027717250236225326}. Best is trial 2 with value: 40.0.\n","output_type":"stream"},{"name":"stdout","text":"Number of finished trials: 3\nBest trial:\n  Value: 40.0\n  Params: \n    batch_size: 32\n    lr: 0.00027717250236225326\nBest model saved to /kaggle/working/models/model_best_resnext.pth\n","output_type":"stream"},{"name":"stderr","text":"Testing: 0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Submission file saved to /kaggle/working/Submission.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}